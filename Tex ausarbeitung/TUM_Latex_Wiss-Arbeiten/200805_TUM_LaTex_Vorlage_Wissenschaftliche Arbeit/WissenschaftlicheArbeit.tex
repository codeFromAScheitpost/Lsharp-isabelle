%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TUM-Vorlage: Wissenschaftliche Arbeit
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Rechteinhaber:
% Technische Universität München
% https://www.tum.de
% 
% Gestaltung:
% ediundsepp Gestaltungsgesellschaft, München
% http://www.ediundsepp.de
% 
% Technische Umsetzung:
% eWorks GmbH, Frankfurt am Main
% http://www.eworks.de
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{./Ressourcen/Praeambel.tex} % !!! NICHT ENTFERNEN !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{./Ressourcen/Anfang.tex} % !!! NICHT ENTFERNEN !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{graphicx}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\usepackage[T1]{fontenc}
\usepackage{isabelle,isabellesym}
\usepackage{aliascnt}
\usepackage{cleveref}



\renewcommand{\figurename}{Figure}
\newcommand{\oquery}{\textnormal{\texttt{OutputQuery}}}
\newcommand{\equery}{\textnormal{\texttt{EquivQuery}}}
\newcommand{\chcons}{\textnormal{\texttt{CheckConsistency}}}
\newcommand{\proccon}{\textnormal{\texttt{ProcCounterEx}}}
\newcommand{\diffquery}{\textnormal{\texttt{DifferenceQuery}}}
\newcommand{\snip}[4]
{\expandafter\newcommand\csname #1\endcsname{#4}}
\input{snippets}


\newenvironment{myisabelle}
{\vspace{-1em}\begin{isabelle}}
	{\end{isabelle}\vspace{-1em}}
\usetikzlibrary{positioning}
\usetikzlibrary {arrows.meta} 

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newcommand*{\definitionautorefname}{Definition}

\begin{document}

\title{Verification of an Automaton Learning Algorithm}
\author{Bruno Philipp}
\date{Datum}
\tableofcontents % Inhaltsverzeichnis

\chapter{Introduction}
In 1956 Edward F. Moore published a paper with the topic of recreating a finite state machine via experiments\cite{gedankenexperiment} where each experiment is a kind of membership query. This was one of the earliest instances of extracting information from a automaton, knowledge of specific states and transitions. Then Tsyh-Wen Pao and John W. Carr expanded this idea with a way to fully describe a Language via experiments. Their algorithm obtains a subset of the Language, with words that exercise every live transition, and has the ability to ask if any string is part of the Language \cite{PAO197853}. While this approach allows for full learning of an Automaton, it is not well suited for black box applications and the subset significantly simplifies the task. To combat this Dana Angluin created of the Minimal Adequate Teacher(MAT) framework \cite{angluin}. In the new MAT framework the idea of membership queries stays but a second kind of query, checking if two languages are equal and returning a counterexample if not, is added. In the same Paper Dana Angluin proposes the $L^*$ algorithm that can learn an automaton in a polynomial amount of queries. Since then the $L*$ algorithm has been used in multiple applications for instance formal Verification of black box Systems \cite{Peled1999}, ... %needs more citations.
 The $L^*$ algorithm has seen many improvements over time \cite{} and different learning algorithms such as TTT \cite{10.1007/978-3-319-11164-3_26}, or algorithms using Homing Sequences \cite{RIVEST1993299} and the $L\#$ algorithm \cite{vandraagerlsharp}. In this thesis we will focus on verifying the $L\#$ algorithm formally. \\
While Frits Vandraager already verified that the $L\#$ algorithm works, this verification was done on paper \cite{vandraagerlsharp}. Proofs on paper are easy to read but can be error prone, for example a proof for the Two-Children problem from Martin Gardener and the proof on three-dimensional simple
orthorhombic Ising lattices by Zhidong Zhang et al. were later found to contain errors\cite{khovanova2011martingardnersmistake, perk2013erroneoussolutionthreedimensional3d}. Formal verification is a way to avoid errors in proofs altogether, one of the earliest formalization, the Principa Mathematica, was done entirely on paper and spans three whole books. It only uses a few axioms and inference Rules to prove a lot of fundamental mathematics. \cite{pincipa} A simple assumption would be that in the framework of the Principa Mathematica every mathematical problem is solvable, but Kurt Gödel showed that there are true statements that are not provable in any formal system \cite{godel}While the formal principles of the Principa Mathematica are already advanced and simple to check, formalizations on paper are long and can still contain errors. Machine checked formalizations can prevent errors, but require difficult programming. To develop a proof one idea is to let the machine reason the whole proof, leading to automatic theorem provers. One example of automatic theorem provers is Vampire, a First order logic solver that gets expanded to this day \cite{vampirediary}, or the SMT solver Z3 that is developed by Microsoft\cite{zthree}. While automatic theorem provers are helpful for simple proofs they struggle with complex proofs \cite{Blaauwbroek_2024}. A more expressive way of proving machine checked are interactive Theorem Provers (ITP). In an ITP the machine and the user work together to achieve a proof, often the ITP also allows access to multiple automatic theorem provers to help achieve a formal proof. Two of the most popular ITPs are Isabelle\cite{paulson2000isabelle700theoremprovers} and HOL light \cite{holligth}. There is a list of 100 arbitrary important mathematical proofs and Isabelle and HOL light lead the comparison of most proven lemmata out of this list \footnote{\url{https://www.cs.ru.nl/~freek/100/}}. The Isabelle theorem prover has been successfully to prove the seL4 micro kernel \cite{sel4}, Generation of LL(1) parsers \cite{LL1_Parser-AFP}, the post quantum cryptography protocol Kyber \cite{CRYSTALS-Kyber-AFP} and many more.\\
\autoref{chap:two} explains the $L\#$ automata learning algorithm for mealy machines. It focuses on the reasoning why different apsects of the algorithm work. \autoref{chap:three} shows the Formalization of the algorithm in Isabelle and explains the core theorems of this formalization.


\chapter{L$\#$} \label{chap:two}
Before discussing the formalization of the $L\#$ algorithm it is important to understand how it works. The following chapter will discuss the algorithm following the explanation of Frits Vandraager et al. in the paper "A New Approach for Active Automata Learning
Based on Apartness" \cite{vandraagerlsharp}.

\section{Functions}
First we define the notation used for functions. We write $f:X\rightharpoonup Y$ to denote that $f$ is a partial function from $X$ to $Y$. To denote that $f$ is defined for a input $x$ we write $f(x)\downarrow$ and to denote that $f$ is undefined for input $x$ we write: $f(x)\uparrow$. 
A function is called total if $f(x)\downarrow$ for all $x$, we write $f:X\rightarrow Y$ to denote that f is a total function from X to Y. The composition of two partial functions $f:X\rightharpoonup Z$ and $g:Y\rightharpoonup Z$ is denoted as $g\circ f:X\rightharpoonup Y$, then the for the composition $g\circ f(x)\downarrow\iff (f(x)\downarrow \land\; g(f(x))\downarrow)$ holds. 

\section{Mealy Machines and apartness}
A Mealy Machine can be understood as a finite state automaton with transitions that can accept different inputs and return outputs. 
\begin{definition}\label{def:Mealy}
	 Any Mealy Machine $M$ is a 6-tuple $M=(Q,q_0,I,O,\delta,\lambda)$where 
\begin{itemize}[itemsep=-8pt, topsep=-20pt]
	\item $Q$ is the finite set of states 
	\item $q_0$ is the initial state 
	\item $I$ is the finite set of input symbols
	\item $O$ is the finite set of output symbols
	\item $\delta :Q\times I\rightharpoonup Q$ the state transition function 
	\item $\lambda :Q\times I\rightharpoonup O$ the output function 
\end{itemize}
\end{definition}
It is important to note that both functions need to be defined on the same inputs $\delta(x)\downarrow\iff\lambda(x)\downarrow$. For combined use of output and transition we use $\langle\lambda,\delta\rangle:Q\times I\rightharpoonup O\times Q$ as the output transition function, e.g. if $\lambda(q,i)=o$ and $\delta(q,i)=q'$ then $\langle\lambda,\delta\rangle(q,i)=(o,q')$. 
 To denote that $\langle\lambda,\delta\rangle(q,i)=(q',o)$ we write $q\xrightarrow{i/o}q'$. Furthermore, to use the transition output function with words of length $n\in\mathbb{N}$ we compose $\langle\lambda,\delta\rangle$ ntimes with itself: 
 
 \begin{definition}\label{def:composition}
 	For a Mealy Machine $M=(Q,q_0,I,O,\delta,\lambda)$ we define the composition of multiple functions $\langle\lambda_n,\delta_n\rangle:Q\times I^n\rightharpoonup O^n\times Q$, inductivley. The base case is defined as the identity function of states with no output: $\langle\lambda_0,\delta_0\rangle=id_Q$ and each step $\langle\lambda_{n+1},\delta_{n+1}\rangle$ using the previous step, and adding one application of the transition output system $\langle\lambda_{n+1},\delta_{n+1}\rangle =Q\times I^{n+1}\xrightharpoonup{\langle\lambda_n,\delta_n\rangle\times id_I}O^n\times Q\times I\xrightharpoonup{id_{O^n}\times\langle\lambda,\delta\rangle} O^{n+1}\times Q$.
 \end{definition} A Mealy Machine is complete if $\delta$ (and therefore $\lambda$) is total. To differentiate between Mealy Machines we the name of the mealy machine as superscript e.g. $M=(Q^M,q_0^M,I,O,\delta^M,\lambda^M)$ or $N=(Q^N,q_0^N,\linebreak I,O,\delta^N,\lambda^N)$.\\
Semantically a state q of a Mealy Machine is a map from input words to output words. 
\begin{definition}\label{definition:semantics}
	 We write $\llbracket q\rrbracket:I^*\times O^*$ where $\llbracket q\rrbracket(\sigma)=\lambda(q,\sigma)$. Two states $q$ and $q'$ are equivalent $q\approx q'$ iff $\llbracket q\rrbracket=\llbracket q' \rrbracket$, both states can be from different Mealy Machines. Two Mealy Machines are equivalent if their initial states are equivalent $M\approx N\iff q_0^M\approx q_0^N$.
\end{definition}
\section{The observation Tree}
For the learning context there are two Mealy Machines, a complete Mealy Machines that the teacher controls $M$ and a partial Mealy Machine $T$ the learner seeks to expand, with transitions that stem from information learned from the teacher. As the partial Mealy Machine seeks to emulate $M$ an undefined transition represents a lack of knowledge. Furthermore the partial Mealy Machine is supposed to act the same way on all defined inputs as the hidden one. We define this behavior as functional simulation:
\begin{definition}\label{def:funcsim}
 For two Mealy Machines $M$ and $N$ the map $f:M\rightarrow N$ is called a functional simulation if: $f\text{ is a map }f:Q^M\rightarrow Q^N \text{ and }
	f(q_0^M)=q_0^N \text{ and } q\xrightarrow{i/o}q' \implies f(q)\xrightarrow{i/o}f(q') 
 $
\end{definition} 
When the algorithm is running each transition it adds also adds a new state, so every state only has one incoming transition. Thus the hidden mealy machine is called a tree, specifically an observation tree.
A Mealy Machine $T$ is a tree if for each $q\in Q^T$ there is a unique accessor $\delta\in I^*$ so that $\sigma^T(q_0^T,\sigma)=q$, we write $accsess(q)=\sigma$. A Tree $T$ is called an Observation tree for a Mealy Machine $M$ if there is a functional simulation $f:T\rightarrow M$.



\begin{figure}[t]

	\begin{subfigure}[b]{0.40\textwidth}
	
	\begin{tikzpicture}[remember picture,
		roundnode/.style={circle, draw=black, fill=white, very thick, minimum size=7mm},
every path/.style={line width=1pt},
every arrow/.style={scale=1.5}
		]
		%Nodes
		\node[roundnode,fill=red!20](two) {2};
		\node[roundnode,fill=blue!20](one)[above=2cm of two] {1};
		\node[roundnode,fill=green!20](three)[right=2cm of two] {3};
		
		
		%Lines
		\draw[->] (0,3.5) -- (one.north);
		\draw[->] (one.south) -- (two.north) node[midway, right] {a/B};
		\draw[->] (one.south) -- (three.north) node[midway,above right] {b/A};
		\draw[->] (two.east) 	.. controls +(up:5mm) and +(up:5mm) ..(three.west) node[midway, above] {a/A};
		\draw[->] (three.west) 	.. controls +(down:5mm) and +(down:5mm) ..(two.east) node[midway, above] {a/B};
		\draw[->] (three.north) 
		.. controls +(up:1cm) and +(right:2cm) .. 
		(one.east)
		node[midway, above right] {b/B};
		\draw[->] (two.north) 	.. controls +(left:7mm) and +(left:7mm) ..(one.south) node[midway, left] {b/B};
	\end{tikzpicture}
	\caption{A Mealy Machine $M$}
	\label{otree:Mealy}
\end{subfigure}
\begin{subfigure}[b]{0.50\textwidth}
	\centering
	\begin{tikzpicture}[remember picture, row sep=2.5em, 		roundnode/.style={circle, draw=black, very thick, minimum size=7mm},
		every path/.style={line width=1pt},
		every arrow/.style={scale=1.5}]
			%Nodes
		\node[roundnode,fill=blue!20](start) {$\epsilon$};
		\node[roundnode,fill=green!20](b)[ below right=7mm and 1.5cm of start]{b};
		\node[roundnode,fill=red!20](a)[above=1.5cm of b]{a};
		\node[roundnode,fill=blue!20](bb)[right=1.5cm of b]	{bb};
		\node[roundnode,fill=green!20](bbb)[right=1.5cm of bb]	{bbb};
		\node[roundnode,fill=red!20](bba)[above=1.2cm of bbb]	{bba};
		
		%Lines
		\draw[->] (-0.8,0) -- (start.west);
		\draw[->] (start.east) -- (a.west) node[midway, above left] {a/B};
		\draw[->] (start.east) -- (b.west) node[midway, above right] {b/A};
		\draw[->] (b.east) -- (bb.west) node[midway, above] {b/B};
		\draw[->] (bb.east) -- (bbb.west) node[midway, above] {b/A};
		\draw[->] (bb.east) -- (bba.west) node[midway, above left] {a/B};

		
\end{tikzpicture}
	\caption{An observation tree $T$ for $M$ with accessor as node names}
	\label{otree:otree}
\end{subfigure}
\begin{tikzpicture}[remember picture, overlay,	every path/.style={line width=1pt},
	every arrow/.style={scale=1.5}]
	% Arrow from a manual position near subfigure 1 to subfigure 2
	\draw[->]
	([xshift=-10cm, yshift=-3cm]current page.north east) 
	to
	([xshift=7.5cm, yshift=-3cm]current page.north west) node[above right] {\qquad\qquad$f$};
\end{tikzpicture}
\caption{an observation tree simulates a Mealy }
\label{otree:main}
\end{figure}
\autoref{otree:main} shows a complete Mealy Machine for $I^M=\{a,b\}$ as well as an observation tree $T$ for $M$. The nodes of $T$ are labeled with their respective accessor, e.g. $\sigma^T(q_0^T,bb)=[bb]$. Because $T$ is an observation tree there exists an $f$ that is a functional simulation from $T$ to $M$ $f:T\rightarrow M$, and each node in the observation tree has the color of the node that it corresponds with in $M$ for example the functional simulation in \autoref{otree:main} the node labled with $a$ corresponds to the node labeled with 2 in the Mealy Machine: $f([a])=2$.\\
Throughout the learning algorithm, the Observation Tree $T$ expanded, but the functional simulation is unknown because the learner has no information about $M$. Thus a metric is needed to produce a Mealy Machine that could be matching the hidden Mealy. With knowledge learned the algorithm can infer that two states can not correspond to the same state of the hidden , e.g. it can infer that $f([b])\neq f([])$ because $\lambda^T([b],b)=B$ and $\lambda^T([],b)=A$. We call this form of inequality apartness. 
\begin{definition} \label{def:apart}
	For a Mealy Machine $M$, two states $p,q\in Q^M$ are apart (written $p\#q$) if there is some $\sigma\in I^*$ such that $\llbracket p\rrbracket(\sigma)\downarrow\land\llbracket q\rrbracket(\sigma)\downarrow$ and $\llbracket p\rrbracket(\sigma)\neq\llbracket q\rrbracket(\sigma)$. The word $\sigma$ is a witness for $p\#q$, we write $\sigma\vdash p\#q$.
\end{definition}
Because the apartness relation notes a difference in the semantics of two states, two apart states can not be mapped to the same state in a functional simulation $f:T\rightarrow M$. $$
p\#q, p,q\in Q^T\implies f(q)\not\approx f(p)
$$
Thus whenever the learner knows that two states are apart in the observation tree, it knows that these are corresponding to different states in the hidden Mealy Machine.
\section{The learning Algorythm $L\#$}

With the invention of automata learning Dana Angluin also proposed the minimal adequate teacher framework. In this framework, the teacher is able to answer two types of queries accurately: a membership query, that allows to check if a string is in a hidden set and a equivalence query, checking if an automaton is equal to the hidden one. The second query allows the learner to ask if their description of a set produces the same set as the hidden set, if the answer is false the teacher also responds with a counterexample why the sets are not the same.\cite{angluin}\\
For the purpose of learning a hidden Mealy Machine we define the two types of query's as follows:
\begin{definition}\label{def:queries}
	in the learning game between a teacher and a learner where the teacher has knowledge of a hidden Mealy Machine $M$and answers the following querys correctly:
	\begin{gather*}\oquery(\sigma): \text{ for }\sigma\in I^*\text{ the teacher replies with the output sequence } \lambda^M(q_0^M,\sigma)\in O^*\\
	\equery(H):\text{ for a complete Mealy Machine } H \text{ the teacher replies with yes if }H\approx M\\\text{ or no and a counterexample } \sigma\in I^*\text{ with }\lambda^M(q_0^M,\sigma)\neq\lambda^H(q_0^H,\sigma)
	\end{gather*}
\end{definition}
The output query lets the algorithm expand its observation tree along a chosen route $\sigma$, and the equivalence query can help if the algorithm can no longer ask productive output query's, but a the observation tree needs to be transformed to a Mealy Machine and the counterexample needs to be processed.

\subsection{Frontier, Basis and Norm}
The $L\#$ algorithm describes the learner in the learning process. The algorithm operates on an observation tree $T=(Q^T,q_0^T,I,O,\delta^T,\lambda^T)$ for the hidden Mealy Machine $M$. Furthermore, the learner knows $I$ and $O$ of the hidden Mealy Machine and uses them for the Observation Tree. 
The algorithm splits $T$ into three sets:
\begin{enumerate}
	\item The Basis $S\subseteq Q^T$ states which have already been identified. The learner knows that each state in $S$ represents a distinct state in $M$. The Basis always contains the starting state $q_0^T\in S$ so initially: $S=\{q_0^T\}$. Since all states in $S$ are different states in the hidden Mealy Machine the learner only adds states to the Basis that are pairwise apart: $\forall p,q\in S, p\neq q: p\#q$.
	\item The Frontier $F\subseteq Q^T$ which are candidates to be added to S. Rather than changing the contents of $F$ manually the learner defines that $F:=\{q'\in Q\mid \exists q\in S, q'\notin S, i\in I: q'=\delta(q,i)\}$.
	\item The remaining states $Q^T\backslash(S\cup F)$.
\end{enumerate}
The algorithm aims to extend the Basis with states from the Frontier until there exists a state in $S$ for each equivalence class in $M$. The algorithm achieves this through the application of four Rules. We will describe the algorithm as applying the four Rules non-determanistically, until no Rule can be applied anymore. The algorithm adds the response of every $\oquery(\sigma)$ to the observation tree. To argue about runtime and termination we define a Norm that is bound and that each Rule application increases. We define the Norm $N(T)$: 
$$
N(t)=\frac{|S|\cdot(|S|+1)}{2}+|\{(q,i)\in S\times I\mid \delta^T(q,i)\downarrow\}|+|\{(q,q')\in S\times F\mid q\#q'\}|
$$
Every Rule we define later will increase one of those summands, the first Rule increases the first summand, the second Rule increases the second summand and the third and fourth Rule increase the last summand.
The first summand is exponentially proportional to the number of states in the Basis, because adding states to the Basis removes them from the Frontier, causing a drop in the third summand. The second summand tracks the number of defined transitions for each state in s, this is increased as states get added to the Frontier. The last summand tracks the apartness relationship between $S$ and F. For an observation tree $T$ for a Mealy Machine $M$ with $n$ equivalence classes and $|I|=k$ the Norm is bound. $$N(T)\leq\frac{n\cdot(n+1)}{2}+kn+(n-1)(kn+1)$$ %%+1 is not neccecary for kn+1 ask if removed
intuitively: if each two states in $S$ are pairwise apart and there exists a functional simulation $f:T\rightarrow M$ than there can only be as many states in $S$ as there are equivalence classes in $M$. As $I$ is static and $F$ can only have $|S\times I|=|S|\cdot|I|$ states.\\

We will discuss each Rule and how they increase the Norm separately. 
To choose states the algorithm uses different metrics for states:
\begin{definition}\label{def:isolated}
	In an observation tree $T$ a state $q\in F$ is called isolated if it is apart from all states in $S$: $\forall p\in S, q\#p$,$q$ identified if it is apart from all but one state in $S$: $\exists p\in S, \neg q\#p, \forall s\in S, s\neq p: q\#s$. The Basis $S$ is complete if each state in $S$ has a transition for every input in $I$: $\forall q\in S, i\in I: \delta(q,i)\downarrow$
\end{definition}

\subsection{Adding states to the Basis (Rule 1)}

The algorithm uses Rule 1 to adds states from $F$ to $S$, it is important to note that adding $q$ to $S$ also removes it from $F$. 
 The Algorithm chooses an isolated state $q\in F, \forall p\in S: q\#p$ nondeterministically, and then adds them to the Basis $S'=S\cup\{q\}$ because it fulfills the requirement for states in the Basis. Because the algorithm chooses $q$ from the Frontier $F$, $S$ can remain a subtree of $T$. The Norm increases as the first term of the Norm has changed to $\frac{(|S|+1)(|S|+1+1)}{2}=\frac{|S|(|S|+1)}{2}+|S|+1$. The second term can only get bigger when $S$ grows, and the third term can shrink when a state from $F$ is removed. Because $q$ was apart from all states in $S$ and we have no information about the apartness of $q$ and the states in $F$. In the worst case the state $q$ is not apart from any state in $F$ thus $|\{(p,p')\in (S\cup \{q\})\times (F\setminus \{q\})| p\#p'\}|\geq |\{(p,p')\in S\times F| p\#p'\}|-|S|$the norm increases in the worst case by one. To characterize the whole Rule we write $$
isolated\: q \text{ for some } q\in F \rightarrow S\leftarrow S\cup\{q\}
$$ 

\begin{figure}[t!]
	\begin{subfigure}[b]{0.45\textwidth}
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start1) {$\epsilon$};
			\node[frontier](b)[ below left=1.5cm and 7mm of start1]{$b$};
			\node[frontier](a)[right=1.5cm of b]{$a$};
			\node[else](bb)[below=1.5cm of b]	{$bb$};
			
			%Lines
			\draw[->] ([yshift=4mm,]start1.north) -- (start1.north);
			\draw[->] (start1.south) -- (a.north) node[midway, above right] {a/B};
			\draw[->] (start1.south) -- (b.north) node[midway,above left] {b/A};
			\draw[->] (b.south) -- (bb.north) node[midway, left] {b/B};
		\end{tikzpicture}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\textwidth}
		
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start2) {$\epsilon$};
			\node[Basis](b)[ below left=1.5cm and 7mm of start2]{$b$};
			\node[frontier](a)[right=1.5cm of b]{$a$};
			\node[frontier](bb)[below=1.5cm of b]	{$bb$};
			
			%Lines
			\draw[->] ([yshift=4mm,]start2.north) -- (start2.north);
			\draw[->] (start2.south) -- (a.north) node[midway, above right] {a/B};
			\draw[->] (start2.south) -- (b.north) node[midway,above left] {b/A};
			\draw[->] (b.south) -- (bb.north) node[midway, left] {b/B};
		\end{tikzpicture}
	\end{subfigure}
	\begin{tikzpicture}[remember picture, overlay,	every path/.style={line width=1pt},
		every arrow/.style={scale=1.5}]
		% Arrow from a manual position near subfigure 1 to subfigure 2
		\draw[->]
		([xshift=1cm,]start1.east)
		to
		([xshift=-1cm,]start2.west) node[above ] {\kern-10em Rule 1};
	\end{tikzpicture}
	\caption{ application of Rule 1 with Basis states marked \textbf{red} and Frontier states marked \textbf{blue}}
	\label{Rule 1fig:main}
\end{figure}
\autoref{Rule 1fig:main} showsan application of Rule 1, it shows an observation tree $T$ of the mealy machine shown in \autopageref{otree:main}. Since the sate labled $b$ is apart from the starting state $b\#\epsilon$ and the state labeled $\epsilon$ is the only state in the Basis, the Rule extends the Basis by adding the state $b$: $S'=S\cup{b}$, then states following $b$ are also added to the Frontier. Nothing else changes in the application of Rule 1.

\subsection{Expanding the Frontier (Rule 2)}
To expand the Frontier the algorithm uses Rule 2. Rule 2 chooses a Basis state $q\in S$ that where the transition for the input $i\in I$ is undefined i.e. $\delta^T(q,i)\uparrow$. Then it asks an output query with the accessor $\sigma=access(q)$ and the input: $\oquery(\sigma\cdot i)$ (where $\cdot$ denotes the concatenation of two words) to the teacher. Then the Rule adds the information, gained by the output query, to the tree, so that $\delta^T(q,i)\downarrow$. No other information is gained, as the values along the path of $\sigma$ are already defined $\oquery(\sigma)=\llbracket q_0^T\rrbracket(\sigma)$. This Rule only adds a state to the Frontier. Because it does not change the Basis, the first summand of the Norm remains unchanged, the second summand increases by one, because a new follow state of the Basis was introduced, and the last summand can only grow, as the apartness relationship can only grow, and no states are removed from $S$ or $F$. the whole Rule can be written as:
$$
\delta^T(q,i)\uparrow, \text{ for some } q\in S, i\in I\rightarrow \texttt{\oquery}(access(q)i)
$$
\autoref{Rule 1fig:main} shows an application of Rule 2. It shows that for state $b$ the transition with input $a$ is missing. So Rule 2 constructs the accessor $\sigma=access(b)=b$ and asks the teacher the query $\oquery(\sigma a)=\oquery(ba)=AB$. Then it extends the tree with the new information. Because the new state it is a follow state of $b$ which is a Basis state, the Rule adds the new state to the Frontier.
\begin{figure}[t!]
	
	\begin{subfigure}[b]{0.45\textwidth}
		
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start2) {$\epsilon$};
			\node[Basis](b)[ below left=1.5cm and 7mm of start2]{$b$};
			\node[frontier](a)[right=1.5cm of b]{$a$};
			\node[frontier](bb)[below=1.5cm of b]	{$bb$};
			
			%Lines
			\draw[->] ([yshift=4mm,]start2.north) -- (start2.north);
			\draw[->] (start2.south) -- (a.north) node[midway, above right] {a/B};
			\draw[->] (start2.south) -- (b.north) node[midway,above left] {b/A};
			\draw[->] (b.south) -- (bb.north) node[midway, left] {b/B};
		\end{tikzpicture}
	\end{subfigure}
	\begin{subfigure}[b]{0.54\textwidth}
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start3) {$\epsilon$};
			\node[Basis](b)[ below left=1.5cm and 7mm of start3]{$b$};
			\node[frontier](a)[right=1.5cm of b]{$a$};
			\node[frontier](bb)[below=1.5cm of b]	{$bb$};
			\node[frontier](ba)[right=1.5cm of bb]	{$ba$};
			
			%Lines
			\draw[->] ([yshift=4mm,]start3.north) -- (start3.north);
			\draw[->] (start3.south) -- (a.north) node[midway, above right] {a/B};
			\draw[->] (start3.south) -- (b.north) node[midway,above left] {b/A};
			\draw[->] (b.south) -- (bb.north) node[midway, left] {b/B};
			\draw[->] (b.south) -- (ba.north) node[midway, above right] {a/B};
		\end{tikzpicture}
	\end{subfigure}
	\begin{tikzpicture}[remember picture, overlay,	every path/.style={line width=1pt},
		every arrow/.style={scale=1.5}]
		% Arrow from a manual position near subfigure 1 to subfigure 2
		\draw[->]
		([xshift=1cm,]start2.east)
		to
		([xshift=-1cm,]start3.west) node[above ] {\kern-10em Rule 2} node[below ] {\kern-10em \oquery(ba)};
	\end{tikzpicture}
	\caption{ application of Rule 1 with states in $S$ marked \textbf{red} and states in $F$ marked \textbf{blue}}
	\label{Rule 2fig:main}
\end{figure}
\subsection{Isolating Frontier States (Rule 3)}
The algorithm now has Rules for adding states to the Basis and to the Frontier, the last two Rules aim to increase the apartness relationship. Explicitly, Rule 3 aims to identify the states in the Frontier. To extend the apartness relationship the Rule chooses a state $q$ that is not apart from two states $r,r'\in S, r\neq r':\neg q\#r,\neg q\#r'$. Because both states are part of the Basis they have to be apart so the algorithm chooses a witness $\sigma\vdash r\#r'$. Following that the algorithm asks the teacher the query $\oquery(access(q)\sigma)$. after this query it adds the new knowledge to the tree. Now either $\sigma\vdash q\#r$ or $\sigma\vdash q\#r'$ must hold, because $\llbracket r\rrbracket(\sigma)\neq\llbracket r' \rrbracket (\sigma)$. Thus the third summand of the Norm increases, and the first and second summand remain unchanged, because no states are added or removed from $S$ or $F$. We can write the whole Rule as $$
\neg (q\#r),\neg(q\#r'),\delta\vdash r\#r' \text{ for some } q\in F, r,r'\in S, \delta\in I^* r\neq r' \rightarrow \oquery(access(q) \delta)
$$
\autoref{Rule 3fig:main} shows the two states of the Basis $b,\epsilon\in S$ are apart with witness $b\vdash\epsilon\#b$. Each state in the Frontier is not apart from both Basis states. The algorithm now can apply Rule 3 once for every state in $F$. \autoref{Rule 3fig:main} shows the application Rule 3 to the node $a$ first, to achive that Rule 3 performs the query \oquery(ab) performed and the query returns $BB$. After this query $b\vdash a\#\epsilon$ holds. Next state bb gets chosen resulting in the query \oquery(bbb), that returns $ABA$. This query has expended the apartness relationship, now $bb\#b$ holds. After this the algorithm could apply Rule 3 again be chosen for the state $ba$ but in this example it does not. 
\begin{figure}[t]
	\begin{subfigure}[b]{0.3\textwidth}
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start1) {$\epsilon$};
			\node[Basis](b)[ below left=1.5cm and 7mm of start1]{$b$};
			\node[frontier](a)[right=1.5cm of b]{$a$};
			\node[frontier](bb)[below=1.5cm of b]	{$bb$};
			\node[frontier](ba)[right=1.5cm of bb]	{$ba$};
			
			%Lines
			\draw[->] ([yshift=4mm,]start1.north) -- (start1.north);
			\draw[->] (start1.south) -- (a.north) node[midway, above right] {a/B};
			\draw[->] (start1.south) -- (b.north) node[midway,above left] {b/A};
			\draw[->] (b.south) -- (bb.north) node[midway, left] {b/B};
			\draw[->] (b.south) -- (ba.north) node[midway, above right] {a/B};
			\path (current bounding box.south) ++(0,-1.5cm) coordinate (dummy);
		\end{tikzpicture}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start2) {$\epsilon$};
			\node[Basis](b)[ below left=1.5cm and 7mm of start2]{$b$};
			\node[frontier](a)[right=1.5cm of b]{$a$};
			\node[frontier](bb)[below=1.5cm of b]	{$bb$};
			\node[frontier](ba)[right=7mm of bb]	{$ba$};
			\node[else](ab)[right =7mm of ba]	{$ab$};
			
			%Lines
			 \draw[->] ([yshift=4mm,]start2.north) -- (start2.north);
			\draw[->] (start2.south) -- (a.north) node[midway, above right] {a/B};
			\draw[->] (start2.south) -- (b.north) node[midway,above left] {b/A};
			\draw[->] (b.south) -- (bb.north) node[midway, left] {b/B};
			\draw[->] (a.south) -- (ab.north) node[midway, above right] {b/B};
			\draw[->] (b.south) -- (ba.north) node[midway, above right] {a/B};
			\path (current bounding box.south) ++(0,-1.5cm) coordinate (dummy);
		\end{tikzpicture}
		
	\end{subfigure}
		\begin{subfigure}[b]{0.3\textwidth}
		
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start3) {$\epsilon$};
			\node[Basis](b)[ below left=1.5cm and 7mm of start3]{$b$};
			\node[frontier](a)[right=1.5cm of b]{$a$};
			\node[frontier](bb)[below=1.5cm of b]	{$bb$};
			\node[frontier](ba)[right=7mm of bb]	{$ba$};
			\node[else](ab)[right =7mm of ba]	{$ab$};
			\node[else](bbb)[below =7mm of bb]	{$bbb$};
			
			%Lines
			 \draw[->] ([yshift=4mm,]start3.north) -- (start3.north);
			\draw[->] (start3.south) -- (a.north) node[midway, above right] {a/B};
			\draw[->] (start3.south) -- (b.north) node[midway,above left] {b/A};
			\draw[->] (b.south) -- (bb.north) node[midway, left] {b/B};
			\draw[->] (a.south) -- (ab.north) node[midway, above right] {b/B};
			\draw[->] (b.south) -- (ba.north) node[midway, above right] {a/B};
			\draw[->] (bb.south) -- (bbb.north) node[midway,left] {b/A};
		\end{tikzpicture}
		
	\end{subfigure}
		 \begin{tikzpicture}[remember picture, overlay,	every path/.style={line width=1pt},
		every arrow/.style={scale=1.5}]
		% Arrow from a manual position near subfigure 1 to subfigure 2
		\draw[->]
		([xshift=1cm,]start1.east)
		to
		([xshift=-1cm,]start2.west) node[above ] {\kern-5em Rule 3} node[below ] {\kern-5em\oquery(ab)};
		\draw[->]
		([xshift=1cm,yshift=1.5mm]start2.east)
		to
		([xshift=-1cm,]start3.west) node[above ] {\kern-5em Rule 3} node[below ] {\kern-5em\oquery(bbb)};
	\end{tikzpicture}
	\caption{application of Rule 3 with states in $S$ marked \textbf{red} and states in $F$ marked \textbf{blue}}
	\label{Rule 3fig:main}
	\end{figure}

\subsection{Verifying the Basis (Rule 4)}
When only applying Rule 1-3 the algorithm reaches a state where no \oquery\space can reliably increase the norm. Thus the algorithm needs to perform an \equery\space to the teacher. Since the \equery\space requires a complete Mealy , the algorithm needs to construct one from the knowledge stored in the observation tree. We call the constructed Mealy Machine a Hypothesis $H$.\\
In particular The algorithm wants Hypothesis $H$ with a functional simulation $f:T\rightarrow H$, as there is a functional simulation to the hidden Mealy Machine. We call such a hypothesis consistent. To construct our Hypothesis the algorithm takes the states from the Basis as states for the hypothesis $Q^H=S $, because the states in $S$ correspond to distinct states in the hidden Mealy Machine. The transitions between Basis states remain the same. For transitions leaving the Basis $q\in S, p\notin S, q\xrightarrow{i/o}p$, the algorithm needs to loop them back into the Basis. Since each follow state of the Basis is a state of the Frontier, the algorithm defines a map $h:F\rightarrow S$ to define the new target of the transition making it $q\xrightarrow{i/o}h(p)$. To create a hypothesis that could be consistent $\neg f\#h(f)$ needs to hold for every $f\in F$. 
\begin{definition} \label{def:hypo}
	Let $T$ be an obseravtion tree with Basis $S$ and Frontier $F$
	\begin{enumerate}
		\item A Mealy Machine $H$ contains the Basis if $Q^H=S$ and $\delta^H(q_0^H,access(q))=q$ for all $q\in S$
		\item\label{def:hypo:two} A hypothesis is a complete Mealy Machine $H$ containing the Basis such that $q\xrightarrow{i/o'}p'$ in $H, (q\in S)$ and $q\xrightarrow{i/o}p$ in $T$ imply $o=o'$ and $\neg (p\#p')$ (in $T$)
		\item A hypothesis H is consistent if there is a functional simulation $f:T\rightarrow H$
		\item For a Mealy Machine $H$ containing the Basis, we say that an input sequence $\sigma\in I^*$ leads to a conflict if $\delta^T(q_0^T,\sigma)\#\delta^H(q_0^H,\sigma)$ (in $T$)
	\end{enumerate}
\end{definition}
An Hypothesis can only exists, if no isolated state $p\in F$ exists, and for every Basis state $q\in S$ and input $i\in I$ the transition is defined $\delta(q,i)\downarrow$, as there does not exist a choice that satisfies \hyperref[def:hypo:two]{Definition 9.2} otherwise. 


\begin{figure}[t]
	\begin{subfigure}[b]{0.3\textwidth}
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
	else/.style={circle, draw=black, very thick, minimum size=7mm}, 
	every path/.style={line width=1pt},
	every arrow/.style={scale=1.5}]
	%Nodes
	\node[Basis](start1) {$\epsilon$};
	\node[Basis](b)[ below left=1.5cm and 7mm of start1]{$b$};
	\node[frontier](a)[right=1.5cm of b]{$a$};
	\node[frontier](bb)[below=1.5cm of b]	{$bb$};
	\node[frontier](ba)[right=7mm of bb]	{$ba$};
	\node[else](ab)[right =7mm of ba]	{$ab$};
	\node[else](bbb)[below =7mm of bb]	{$bbb$};
	
	%Lines
	\draw[->] ([yshift=4mm,]start1.north) -- (start1.north);
	\draw[->] (start1.south) -- (a.north) node[midway, above right] {a/B};
	\draw[->] (start1.south) -- (b.north) node[midway,above left] {b/A};
	\draw[->] (b.south) -- (bb.north) node[midway, left] {b/B};
	\draw[->] (a.south) -- (ab.north) node[midway, above right] {b/B};
	\draw[->] (b.south) -- (ba.north) node[midway, above right] {a/B};
	\draw[->] (bb.south) -- (bbb.north) node[midway,left] {b/A};
\end{tikzpicture}
	\end{subfigure}
		\begin{subfigure}[b]{0.3\textwidth}
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start1) {$\epsilon$};
			\node[Basis](b)[ below left=1.5cm and 7mm of start1]{$b$};
			\node[frontier](a)[right=1.5cm of b]{$a$};
			\node[frontier](bb)[below=1.5cm of b]	{$bb$};
			\node[frontier](ba)[right=7mm of bb]	{$ba$};
			\node[else](ab)[right =7mm of ba]	{$ab$};
			\node[else](bbb)[below =7mm of bb]	{$bbb$};

			%Lines
			 \draw[->] ([yshift=4mm,]start1.north) -- (start1.north);
			\draw[->] (start1.south) -- (a.north) node[midway, above right] {};
			\draw[->] (start1.south) -- (b.north) node[midway,above left] {};
			\draw[->] (b.south) -- (bb.north) node[midway, left] {};
			\draw[->] (a.south) -- (ab.north) node[midway, above right] {};
			\draw[->] (b.south) -- (ba.north) node[midway, above right] {};
			\draw[->] (bb.south) -- (bbb.north) node[midway,left] {};
			\draw[->] (ba.east) .. controls +(0.7cm,1cm)..(b.east) node[midway,right] {h};
			\draw[->] (ba.east) .. controls +(3cm,-2cm)..(start1.east) node[midway,right] {h'};
			\draw[->] (a.west) -- (b.east) node[midway,above] {h/h'};
			\draw[->] (bb.west) .. controls +(-1cm,3cm)..(start1.west) node[midway,left] {h/h'};
		\end{tikzpicture}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start2) {$\epsilon$};
			\node[Basis](b)[ below right =1.5cm and 7mm of start2]{$b$};
			\node[Basis](start3) [ below =1.5cm of b]{$\epsilon$};
			\node[Basis](bnew)[ below right=1.5cm and 7mm of start3]{$b$};
			
			
			%Lines
			 \draw[->] ([yshift=4mm,]start2.north) -- (start2.north);
			\draw[->] (start2.south) -- (b.north) node[midway,below left] {b/A, a/B};
			\draw[->] (b.south) .. controls +(0.7cm,-0.5cm) and +(-0.7cm,-0.5cm) .. (b.south) node[midway,below]{a/B};
			\draw[->] (b.east) .. controls +(0.8cm,0cm).. (start2.south) node[midway,right]{b/B};
			 \draw[->] ([yshift=4mm,]start3.north) -- (start3.north);
			 	\draw[->] (start3.south) -- (bnew.north) node[midway,above right] {b/A, a/B};
			 	\draw[->] (bnew.west) .. controls +(-0.8cm,0cm).. (start3.south) node[midway,below left]{b/B, a/B};
		\end{tikzpicture}
	\end{subfigure}
	
		
	
	
	\caption{a observation tree (left) two possible choice functions (middle) and two hypothesis(right) one for h (above) and one for h' (below) }
	\label{hypofig:main}
\end{figure}
\autoref{hypofig:main} shows the observation tree, and two choice functions $h:F\rightarrow S, h':F\rightarrow S$ which leads to the twoHypothesis. Because one state is unidentified two different hypothesis are possible.\\ 
Now, the algorithm has a complete Mealy machine, so it can start an \equery. Because long counterexamples are difficult to process Equivalence querys can be expensive. Thus the algorithm checks first if the hypothesis is consistent with the observation tree. To check for consistency the algorithm uses a procedure \chcons. \chcons \space is checking that each state existing in the tree is not apart from the state reached via the same input in the hypothesis. The procedure does this via a breadth first search on the observation tree. If any two states $q\in Q^T, p \in S$ are apart on this search, the $access(q)$ can be taken as a counterexample four the hypothesis. The specific procedure can be seen in \autoref{algo:checkCons}
\begin{algorithm}[b]
	\caption{check if hypothesis $H$ is consistent with observation tree $T$}
	\label{algo:checkCons}
	\begin{algorithmic}
		\Procedure{CheckConsistency}{$H$}
		\State Q $\gets$ \textbf{new} queue $\subseteq Q^T \times S$
		 \State $enqueue(Q,(q_0^T,q_0^H))$
		 \While{$(q,r)\gets dequeue(Q)$}
		 	\If{$q\#r$}
		 	\Return no: $access(q)$
		 	\EndIf
		 	\ForAll{$q\xrightarrow{i/o}p$ in $T$}
		 	\State $enqueue(Q,(p,(\delta^H(r,i))))$
		 	\EndFor
		 \EndWhile
		 \Return yes
		 \EndProcedure
	\end{algorithmic}
\end{algorithm}

\begin{figure}[t]
	\begin{subfigure}[b]{0.45\textwidth}
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start1) {$\epsilon$};
			\node[Basis](b)[ below left=1.5cm and 7mm of start1]{$b$};
			\node[frontier](a)[right=1.5cm of b]{$a$};
			\node[frontier](bb)[below=1.5cm of b]	{$bb$};
			\node[frontier](ba)[right=7mm of bb]	{$ba$};
			\node[else](ab)[below right =5mm and 7mm of a]	{$ab$};
			\node[else](aba)[below =5mm of ab]	{$aba$};
			\node[else](abaa)[below =5mm of aba]	{$abaa$};
			\node[else](bbb)[below =7mm of bb]	{$bbb$};
			\node[else](bab)[below =7mm of ba]	{$bab$};
			
			%Lines
			 \draw[->] ([yshift=4mm,]start1.north) -- (start1.north);
			\draw[->] (start1.south) -- (a.north) node[midway, above right] {a/B};
			\draw[->] (start1.south) -- (b.north) node[midway,above left] {b/A};
			\draw[->] (b.south) -- (bb.north) node[midway, left] {b/B};
			\draw[->] (a.south) -- (ab.north) node[midway, above right] {b/B};
			\draw[->] (b.south) -- (ba.north) node[midway, above right] {a/B};
			\draw[->] (bb.south) -- (bbb.north) node[midway,left] {b/A};
			\draw[->] (ba.south) -- (bab.north) node[midway,right] {b/B};
			\draw[->] (ab.south) -- (aba.north) node[midway,right] {a/B};
			\draw[->] (aba.south) -- (abaa.north) node[midway,right] {a/A};
		\end{tikzpicture}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\textwidth}
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start2) {$\epsilon$};
			\node[Basis](b)[ below left=1.5cm and 7mm of start2]{$b$};
			
			
			%Lines
			 \draw[->] ([yshift=4mm,]start2.north) -- (start2.north);
			\draw[->] (start2.south) -- (b.north) node[midway,above left] {b/A, a/B};
			\draw[->] (b.south) .. controls +(0.7cm,-0.5cm) and +(-0.7cm,-0.5cm) .. (b.south) node[midway,below]{a/B};
			\draw[->] (b.east) .. controls +(0.8cm,0cm).. (start2.south) node[midway,right]{b/B};
			\path (current bounding box.south) ++(0,-3cm) coordinate (dummy);
		\end{tikzpicture}
	\end{subfigure}
	
	
	
	
	\caption{A observation tree leading to a conflict when checking consistency for the observation tree on the right }
	\label{conflict:main}
\end{figure}
\autoref{conflict:main} shows an observation tree that could be produced for the Mealy Machine shown in \autoref{otree:main}, when calling \chcons($H$) it will return $(No,aba)$ as $aba\#b$ and $\delta^H(q_0,aba)=b$. \\
If consistency checking returns yes the algorithm needs to perform the \equery($H$). The answer will either be yes, leading to termination and $H$ being the learned Mealy Machine, or $(no,cex)$ where $cex$ is a counterexample such that $\oquery(cex)\neq\llbracket q_0^H\rrbracket(cex)$. 
Since the length of the counterexample is unknown, the learner needs to process it, to guarantee extension of the apartness relationship.\\
To process counterexamples the algorithm uses a binary search approach cutting the counterexample in half every iteration. The algorithm uses \proccon with the goal that $\proccon(\sigma)$ changes the tree in such a way, that $H$ can never be a Hypothesis for $T$ again. 
For example, the algorithm creates the hypothesis shown in \autoref{hypofig:main}, \equery(H) could return any string $(bb)^nba$ to classify the same issue. If the algorithm adds a long counterexample it could extend the Observation Tree with new information but not expand the apartness relationship. Thus the \proccon needs to find the list of inputs that leads to this conflict. Since $\delta^H(q_0^H,(bb)^n)\# \delta ^T(q_0^T,(bb)^n)$,\proccon\space moves this apartness closer to the Frontier. The exact counterexample processing algorithm is complex and not needed to understand the formalization later on so it will not be explained further here. 

After processing a counterexample, the algorithm knows that a Frontier state is apart from one more Basis state than before. This increases the third summand of the norm. Because the Basis has not changed, the first summand remains the same, and because of the assumption no transition out of the Basis is undefined, the second summand can not change either.\\

\subsection{Simplification of Rule 4}
Rule 4 has proven to be the hardest version to verify formally, thus we propose a simpler version that accomplishes the same. For this simplified versionwe introduce a new type of query: 
\begin{definition}
	Expanding Definition 2.6 the teacher can also answer the following query:
	\begin{gather*}
		\diffquery(p,q): \text{ the teacher replies with yes if:} \neg\delta^M(q_0,p)\#^M\delta^M(q_0,q)\\ \text{ and no and a counterexample } \sigma\in I^* \text{ with } \sigma\vdash\delta^M(q_0,p)\#^M\delta^M(q_0,q) \text{ otherwise.}
	\end{gather*}
\end{definition}
Note that we are referring to specific nodes in the hidden Mealy Machine through an input sequence. Using $\diffquery (access(q),access(p))$ the algorithm can be sure that for a functional simulation $f:T\rightarrow M$ the states reached via functional simulation are semantically equal to the state reached through the accessor: $f(q)\approx \delta^M(q_0,access(q))$. This way the algorithm does not need to produce a hypothesis and can check two states against each other directly. \\
\begin{figure}
	\begin{subfigure}[b]{0.3\textwidth}
		
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start2) {$\epsilon$};
			\node[Basis](b)[ below left=1.5cm and 7mm of start2]{$b$};
			\node[frontier](a)[right=1.5cm of b]{$a$};
			\node[frontier](bb)[below=1.5cm of b]	{$bb$};
			\node[frontier](ba)[right=7mm of bb]	{$ba$};
			\node[else](ab)[right =7mm of ba]	{$ab$};
			\node[else](bbb)[below =7mm of bb]	{$bbb$};
			\node[else](bab)[below =7mm of ba]	{$bab$};
			
			%Lines
			\draw[->] ([yshift=4mm,]start2.north) -- (start2.north);
			\draw[->] (start2.south) -- (a.north) node[midway, above right] {a/B};
			\draw[->] (start2.south) -- (b.north) node[midway,above left] {b/A};
			\draw[->] (b.south) -- (bb.north) node[midway, left] {b/B};
			\draw[->] (a.south) -- (ab.north) node[midway, above right] {b/B};
			\draw[->] (b.south) -- (ba.north) node[midway, above right] {a/B};
			\draw[->] (bb.south) -- (bbb.north) node[midway,left] {b/A};
			\draw[->] (ba.south) -- (bab.north) node[midway,right] {b/B};
		\end{tikzpicture}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		
		\begin{tikzpicture}[remember picture, row sep=2.5em, 		Basis/.style={circle, draw=black, very thick, minimum size=7mm,fill=red!20},frontier/.style={circle, draw=black, very thick, minimum size=7mm,fill=blue!20},
			else/.style={circle, draw=black, very thick, minimum size=7mm}, 
			every path/.style={line width=1pt},
			every arrow/.style={scale=1.5}]
			%Nodes
			\node[Basis](start3) {$\epsilon$};
			\node[Basis](b)[ below left=1.5cm and 7mm of start3]{$b$};
			\node[frontier](a)[right=1.5cm of b]{$a$};
			\node[frontier](bb)[below=1.5cm of b]	{$bb$};
			\node[frontier](ba)[right=7mm of bb]	{$ba$};
			\node[else](ab)[right =17mm of ba]	{$ab$};
			\node[else](aa)[right =7mm of ba]	{$aa$};
			\node[else](bbb)[below =7mm of bb]	{$bbb$};
			\node[else](bab)[below =7mm of ba]	{$bab$};
			
			
			
			%Lines
			\draw[->] ([yshift=4mm,]start3.north) -- (start3.north);
			\draw[->] (start3.south) -- (a.north) node[midway, above right] {a/B};
			\draw[->] (start3.south) -- (b.north) node[midway,above left] {b/A};
			\draw[->] (b.south) -- (bb.north) node[midway, left] {b/B};
			\draw[->] (a.south) -- (ab.north) node[midway, above right] {b/B};
			\draw[->] (a.south) -- (aa.north) node[midway, below left] {a/A};
			\draw[->] (b.south) -- (ba.north) node[midway, above right] {a/B};
			\draw[->] (bb.south) -- (bbb.north) node[midway,left] {b/A};
			\draw[->] (ba.south) -- (bab.north) node[midway,right] {b/B};
			\draw[->] (ba.south) -- (bab.north) node[midway,right] {b/B};
		\end{tikzpicture}
	\end{subfigure}
	\caption{Application of the simplified Rule 4}
	\label{simprul4fig:main}
\end{figure}
Since the algorithm did not create an hypothesis, no consistency checking is possible, leading to further simplification of the Rule . Thus the algorithm needs to ask \diffquery's every time it wants to apply Rule 4. Each application of the simplified Rule 4 needs up to $(|S|*|F|)$ queries, because every state of the Frontier needs to be checked against every state from the Basis. If every state in the Frontier is identified, it only needs $|F|$ queries, because all tuples $(s,f)\in S\times F$ can be ignored. For this nondeterministic approach the algorithm can assume a counterexample and does not need specific searching. If no queries can answer with $No$, the algorithm now knows that it can only construct $H$ that are equal to the hidden mealy machine $H\approx M$. If any $\diffquery(q,p)$ answers with $(no,\sigma)$ the algorithm performs two output querys $\oquery(p\sigma)$ and $\oquery(q\sigma)$,after which $\sigma\vdash\delta^T(q_0^T,q)\#^T\delta^T(q_0^T,p)$ holds. This means the algorithm does not need to process the counterexamples found.\\
For example, \autoref{simprul4fig:main} shows the simplified Rule 4 applied to the observation tree that is generated by applying Rule 3 to the observation tree found in \autoref{Rule 3fig:main}. Now the algorithm compares every state $q\in F$ to the states $p\in S$ where $ q\#p$. Then it asks the queries $\diffquery(access(bb),access(\epsilon)), \diffquery(access(ba),acess(b))$ and 
\newline $\diffquery(access(a),access(b))$. If all of those queries returned yes the algorithm could construct a Hypothesis $H$ where $H\approx M$. When the teacher controls the hidden mealy machine shown in \autoref{otree:main},
$\diffquery(access(ba),acess(b))$ and \newline$\diffquery(access(a),access(b))$ would return $no:cex$ where the shortest $cex=a$ and any other counterexample would decompose into $au$ where $u\in I^*$. Longer counterexamples are possible for more complex hidden s, but for this approach the length of counterexample does not lead to more queries being needed to solve them. \\
\autoref{simprul4fig:main} shows $\diffquery(access(a),access(b))$ being asked first and returns $no:a$ as a reply, then it shows the tree generated when the algorithm asks \oquery(aa) and \oquery(ba), the second query does not change anything, but the first one adds a state leading to $a\vdash a\#b$. Since state $a$ is now isolated and the algorithm can not continue performing Rule 4.


\chapter{Formalization}\label{chap:three}
Based on the inner workings of the L$\#$ algorithm the following chapter covers the formalization. Theorem provers are used to verify formal proofs, a interactive theorem prover lets us write the formal proof in a programming like fashion. We choose Isabelle/HOL for this thesis.
\section{Definitions}
The first Basis is the formalization of the concepts used in the algorithm. 
\subsection{Mealy Machines}
For the formalization we differentiate between complete Mealy Machines and observation trees, because it reduces the amount of information needed to classify the complete Mealy. Here we describe the complete Mealy Machine first. We use a combined output transition function similar to $\langle\lambda,\delta\rangle:Q\times I\rightharpoonup O\times Q$ in the mealy machine. 
\begin{myisabelle}
	\transtype
\end{myisabelle}
Next we define an equivalent for Mealy Machines $M=(Q,q_0,I,O,\delta,\lambda)$ using the trans type as the transition output function. Furthermore the sets of states $Q$, inputs $I$ and outputs $O$are types rather than explicitly adding them to the Mealy Machine constructor. This enforces that any transition is set on the bounds of the defined types, otherwise some invariant would be necessary to show that no transition from the set of states can leave the predefined set. Instantiating a mealy machine only requires $q_0$ and a transition output function.
\begin{myisabelle}
	\mealytype
\end{myisabelle}
Performing a run through the Mealy Machine with a word of length n requires a function similar to $\langle\lambda_n,\delta_n\rangle$. The function \textit{run\_mealy} takes a transition function, a state where the run starts and the input sequence of a run, it then recursively adds an output to the list and returns the output list as well as the state where the run ends.
\begin{myisabelle}
	\runmealy
\end{myisabelle}
For easier reading in more complex proofs we define \textit{outs\_run\_Mealy} and \textit{state\_run\_Mealy} as the functions extracting the output or the reached state from \textit{run\_Mealy}. 
Since \textit{outs\_run\_Mealy f q} is equivalent to $\llbracket q\rrbracket$ we can also define the equality of states similar to the definition in Chapter 2, namely that two states are equal if they produce the same output for every input. Since states can be from different Mealy Machines however we need to specify witch Mealy Machine a state belongs to. The function \textit{eq\_mealy} takes two states and a mealy machine that they belong to and returns $True$ iff both are equal.
\begin{myisabelle}
	\eqmealydef
\end{myisabelle}
The equality of two Mealy Machines is the equality of the two starting states. The \textit{equal} abbreviation takes two mealy machines and compares the starting states, returning true iff those are equal.
\begin{myisabelle}
	\equal
\end{myisabelle}

\subsection{Observation Trees}
After we have defined the hidden Mealy Machine and its functions, we now define the Observation tree. For partial Mealy Machines in a tree shape, we use a datatype that contains a partial function to the following nodes and output. Each node keeps track only of its own followers. This simplifies adding nodes to the transition function. Furthermore the algorithm only needs to keep track of the root node of the tree, traversing it for any operation needed. We will refer to specific nodes by their accessors because the datatype \textit{otree} only contains information about the next transitions. The partial function in Isabelle is realized via the option datatype, where any transition can either contain \textit{None} referring to an undefined transition or \textit{Some (node,output)} where \textit{node} is the next node reached and \textit{output} is the output value. 
\begin{myisabelle}
	\otree
\end{myisabelle}
Similar to \textit{run\_mealy} and $\langle\lambda_n,\delta_n\rangle$ we define the function \textit{run} to traverse the observation tree. \textit{run} will traverse the tree along the input list edges, and return \textit{None} if any edge along the path would be undefined:
\begin{myisabelle}
	\run
\end{myisabelle}
To simplify reading of more complex proofs we define \textit{out\_run} as the output function, however not via \textit{run} but similar to the \textit{run} definition with only the output being returned. This brings the benefit of making inductions easier for proofs where we use \textit{out\_run}.\\
To argue about the effectivness of the algorithm a definition of apartness is also necessary. The definition is similar to \autoref{def:apart}, and because \textit{out\_run q} is equivalent to $\llbracket q\rrbracket$ we replace one with the other in our formal definition. For apartness we refer to each state by the input sequence that is the unique accessor for that state, so the \textit{apart} function takes an observation tree, as Basis for comparing the two nodes and two input lists that refer to a node. It returns \textit{False} if from both nodes there is a sequence of inputs that leads to different outputs and \textit{True} otherwise.
\begin{myisabelle}
	\apart
\end{myisabelle}
In some cases we need to refer a witness of two apart states, for this we describe the function \textit{apart\_witness}. The definition is very similar to the one of \textit{apart} just with i being moved from the existence quantor to the inputs of the function.\\
Following the original definition we also define a functional simulation, but the proof will use it to a lesser extend, it is not part of the invariant, but the invariant we will define dictates that a functional simulation must exist. For the observation tree a functional simulation is defined as a function from an input list to a Mealy Machine state. Furthermore, the definition \textit{func\_sim} classifiesa function $f$ as a functional simulation for Mealy Machine $m$ and observation tree $T$ if it returns \textit{True}. Because states in the observation tree are labeled via input strings, the starting state of any observation tree is $[]$. Otherwise the definition is similar to \autoref{def:funcsim}. 
\begin{myisabelle}
	\funcsim
\end{myisabelle}
\subsection{Further Prerequisites}
After both the Mealy Machine and the Observation tree are properly defined in the formalization, some other helpful functions are needed to perform a run of the algorithm. First we will refer to any output query via a wrapper function \textit{output\_query} expecting a Mealy Machine $M$ and a list of inputs. This function only calls \textit{outs\_run\_Mealy} internally, we do this for readability. \\
When the algorithm asks an \textit{output\_query} it needs to add the new information to the existing tree, the function \textit{process\_output\_query} is responsible for this job. the function \textit{process\_output\_query} takes a root node $T$, one input list as well as an output list of the same length, it traverses the tree along the input edges, and defines any edge that is undefined with the corresponding output. New nodes created by \textit{process\_output\_query} start of as nodes with no transitions. Furthermore we note that \textit{process\_output\_query} is not defined for two lists that don't have the same length. At the end a new root node is returned. 
\begin{myisabelle}
	\procopquery
\end{myisabelle}
To keep track of the current state of the algorithm we define a datatpye \textit{state}. The state contains the Basis, the Frontier and the root node of the observation tree. the Basis and Frontier are defined as \textit{'in list set}'s where each \textit{'in list} refers to one node. Later we see \textit{(S,F,T)} to classify a state most of the time.\\
We have defined the Frontier before as all the follow states of S in the explanation of the algorithm. To tack specific changes, or if no changes need to be made we want to change the Frontier explicitly. Tracking explicit changes of the Frontier in Rule 1 is complicated, because a state gets added to the Basis, and no information about the follow states is given. Thus we define the \textit{frontier} function that returns a Frontier set based on the input of the current state.
 \begin{myisabelle}
 	\frontier
 \end{myisabelle}
To argue about termination and number of Rules applied we also need to define the norm. We split the Norm into three different sections, called \textit{norm1}, \textit{norm2} and \textit{norm3} each function takes a state as an input and corresponds to a summand in the original norm. To build a whole Norm we define a function \textit{norm} adding the three Norm summands together.\\ 
To create a complete Mealy Machine out of the observation tree, a Hypothesis is needed. For the purposes of verifying the algorithm we classify if a Mealy Machine $([],t)$ is a possible hypothesis for the state of our algorithm. A function \textit{hypothesis} takes the state and a transition function $t$ as input. A transition function $t$ can be a hypothesis if for all nodes in the Basis the output for any transition is the same, all transitions between Basis states remain the same and any transition leaving the Basis to a state $f$ leads to a state $q\in S$ and $\neg (f\#q)$.
\begin{myisabelle}
	\hypothesis
\end{myisabelle}
\subsection{The Locale}
For the whole proof we use a locale to fix different variables. We do this to define behavior that is hard to describe in function form, and to make some parts of the proof more readable. First we fix a Mealy Machine $M$, we implicitly fix the types \textit{s'}, \textit{'in} and \textit{'out} for the proof as well. The input type \textit{'in} and state type \textit{'s} are required to be finite, as the algorithm never terminates for some infinite Mealy Machines. Next we fix the set of inputs \textit{I}, we assume that \textit{I} represents the universe of the input type, the set of states \textit{Q} is also fixed in this way. These two sets are fixed for readability as writing \textit{I} is easier to understand than \textit{(UNIV::'in set)}. \\
The proposed difference query is also defined in the locale, because the behaiviour is complex and concrete implementation is not needed to prove the existing algorithm. The described difference query answers with \textit{None} for any two input lists $s$ and $fs$ there does not exist an input $x$ where the two states reached by $s$ and $fs$ produce different outputs, i.e. $\sigma^M(q_0,s)\approx\sigma^M(q_0,s)$. However if the difference query answers with \textit{Some x} then $x$ has to be a counterexample so that $x\vdash\sigma^M(q_0,s)\#\sigma^M(q_0,s) $. Both of those classifications are defined only via \textit{outs\_run\_Mealy}, an only comparing the output not produced by $s$ and $fs$.
\begin{myisabelle}
	\localedef
\end{myisabelle}
\subsection{The Invariant}
Since the algorithm is complex and we make many assumptions about the state of the algorithm, we define a specific invariant that is upheld throughout the execution of the algorithm. The Invariant holds if: 
\begin{itemize}
	\item No node can be in the Frontier and in the Basis at the same time
	\item For all accessors in the Basis the run sequence must be defined
	\item The Frontier and the Basis are finite sets
	\item Each two items in the Basis are pairwise apart (we write \textit{sapart (S,F,T)})
	\item All output sequences the tree can produce must be the same as a output query with the same input would produce
	\item The Frontier is always equal to the defined \textit{frontier} function 
	\item The empty list is in the Basis and any state in the Basis that is not the empty list has to be a state following another state of the Basis
\end{itemize}
Because the invariant is a definition two extra lemata are useful for proofs involving \textit{invar}, one describes how to verify if a state is consistent with the invariant, and one describes what we know about any state that fulfills the invariant.
In isabelle we define the Invariant as a definition \textit{invar}
\begin{myisabelle}
	\invar
\end{myisabelle}
\subsection{The Algorithm}
For verification purposes we describe the algorithm as a transition system, i.e. we only describe when a step from the algorithm is possible. For that we describe a inductive \textit{algo\_step}, that is split in four Rules that correspond to the Rules described before. We use an inductive for the algorithm descriptions as it matches well with the nondeterministic approach described in \autoref{chap:two}, and because we don't need to define functions that return certain inputs we need for each Rule . For example we define \textit{Rule 1}, as: there is a transition from one state $(S,F,T)$ to another state where a node $f$ is added to the Basis and the Frontier being updated, if $f$ is isolated.
\begin{myisabelle}
	\ruleone
\end{myisabelle}
For the transition of the second Rule we write that a transition from $(S,F,T)$ to $(S,F\cup\{s@[i]\},process\_output\_query\: T\: (s@[i])\: out)$ is possible if $s$ is a Basis state and $s@[i]$ is not defined on the observation tree. Then the algorithm performs an output query with the input $s@[i]$ that returns $out$. Here we could also write $process\_output\_query\; T\; (s@[i])\; (output\_query\; M\; (s@[i]) )$ but it would overcrowd the right side of the Rule . 
\begin{myisabelle}
	\ruletwo
\end{myisabelle}
The definition of Rule 3 in Isabelle entails two different Basis states $s1\neq s2, s1,s2\in S$ and a Frontier state $f\in F$. For Rule 3 to be applicable $f$ needs to be apart from both $s1$ and $s2$. The algorithm then takes any witness $w\vdash s1\# s2$ and obtains the result $out$ from the output query with input $f@w$. now a transition from $(S,F,T)$ to $(S,F,process\_output\_query\; T\; (f@w)\; out)$ is possible, and$f$ is apart from at least one of the two states from the Basis. 
\begin{myisabelle}
	\rulethree
\end{myisabelle}
The formalization of Rule 4 requires two calls of \textit{process\_output\_query}, to make sure that the counterexample given by a difference query is defined for both states, so the transition from $(S,F,T)$ to \newline$(S,F,process\_output\_query\; (process\_output\_query \; T \; (s@inp)\; outs) \; (fs@inp)\;outf)$ is possible if:
\begin{itemize}
	\item all transitions coming from a state in the Basis are defined
	\item no state in the Frontier is isolated
	\item $fs$ is a state in the Frontier
	\item $s$ is a state in the Basis
	\item $s$ and $fs$ are not apart
	\item the difference query for $s$ and $fs$ returns a counterexample $inp$
	\item $outs$ and $outf$ are the results of output queries for input $s@inp$ and $fs@inp$ respectively 
\end{itemize}
Following this description the whole \textit{Rule 4} looks like this: 
\begin{myisabelle}
	\rulefour
\end{myisabelle}
\section{Proof}
After we have defined all important functions, we will focus on the lemmata and theorems that are proven in the formalization. Since the formalization required a lot of small lemmata the following chapters will focus on the most important ones and the intuition behind why and how the proofs where conducted. Before inspecting any lemmas in particular we formulate the goal. We want to prove that the transition system \textit{algo\_step} leads to a hypothesis that is equal to the Mealy Machine $M$, we also want to prove that this is possible in a polynomial amount of Rule applications. With these goals in mind the next sections will explain the important lemmata needed to formalize the proof.
\subsection{Retaining the invariant}
The invariant is crucial to describe the behaiviour of the observation tree, for proofs using a state of the algorithm, one assumption will usually be that the state fulfills the requirements for the invariant. To use this invariant throughout the algorithm we need to proof that a step will always retain the invariant. This is why we prove lemma \textit{algo\_step\_keeps\_invar}. This lemma assumes that a state $(S,F,T)$ is consistent with the invariant and there is a step from $(S,F,T)$ to $(S',F',T')$. using those assumptions we need to show that the invariant holds for $(S',F',T')$. 
\begin{myisabelle}
	\retaininvar
\end{myisabelle}
The proof of this lemma focusses on showing every requirement for every possible Rule application seperatley, since if a step is possible one of the four Rules has to be applied. For most requirements this is trivial, butthe conditions relying on specific \textit{outs\_run} behaiviour especially that all output sequences the tree produces are the same as the output query, are more changeling.\\ 
One of the most important lemmas used to argue about different \textit{run\_output} results is \textit{output\_query\_retains\_some\_specific\_output} wich argues that all sequences that are defined on a tree give the same output before and after an output query is processed.The lemma assumes that we use two lists of the same length $ip$ and $op$ and that for a tree \textit{Node $r$} the sequence $acc$ is defined. it then shows that the result of \textit{outs\_run} is the same for the node and the node that has processed an output query with $ip$ as input and $op$ as output for sequence $acc$.
\begin{myisabelle}
	\opqueryretains
\end{myisabelle} 
The proof of this lemma uses an induction on the sequence $acc$. The base case equality is easy to prove it, extending the sequence by one letter $acc'=a \cdot acc$ is more difficult. To prove the induction step the proof differentiatesn $ip$ and $op$ being empty or containing at least one symbol. The empty case is once again trivial, in the other case the proof checks if the first letter of $ip$ and $a$ are equal. If both letters are equal, the proof transforms the goal term to a term only dependent on the output of the Node function with input a: $r(a)$ andthe input $ip$ and output $op$ for \textit{process\_output\_query} without the first letter, then use the induction hypothesis to show equality, otherwise the \textit{process\_output\_query} does not change anything about the output. \\
 We use this lemma in the proof of \textit{algo\_step\_keeps\_invar}. For two states $(S,F,T)$ and $(S,F',T')$ where $T'$ is only different from $T$ through applying \textit{process\_output\_query} functions. We can now show that the invariant requirements involve \textit{outs\_run\_mealy} still hold for $T'$ on the inputs already defined for $T$. For example in the Rules 2-4 the Basis does not change, so the proofs shows the requirement, that every Basis state is defined, with \textit{output\_query\_retains\_some\_specific\_output}. For the requirement that all output sequences are equal to the output query, the proof uses \textit{output\_query\_retains\_some\_specific\_output} to show that all values that were defined on the original tree $T$ are still equal to the \textit{output\_query}. To prove that goal, we also need information about the transitions \textit{process\_output\_query} adds, so we need another lemma.\\
We define a auxiliary lemma\textit{output\_query\_keeps\_invar\_aux} that shows that any input sequence not defined for a tree $T$ will fall in line with the requirement after processing an output query.
\begin{myisabelle}
	\oqueryinvaraux
\end{myisabelle} 
The proof of \textit{process\_output\_query} in isabelle is quite difficult even if the lemma would be easy to do on paper. The main idea of the proof is an induction on the input that was undefined before. Performing the induction step is rather difficult, because to apply the induction hypothesis the proof needs to make some case distinctions. First the proof shows that any sequence that still produces \textit{None} does not need to be considerd, since $False \implies x$ holds for any $x$. Then for the case that the sequences $is=a\cdot i$ does not produce none, the proof needs to consider the first step in the original tree, if $T=Node\; f$ the proof considers two cases if $f\; a = Some\; c$ the proof reformulates the goal case in a way that allows it to apply the inudction hypothesis. If $f\; a=None$ even further case distinctions are needed, specifically only the case that $i$ is not empty is interesting for the proof, where it uses the induction hypothesis once again, with a empty node.\\
The requirement of eqaulity to \textit{output\_query} for \textit{algo\_step\_keeps\_invar} now gets solved thorugh applying the new lemma. the proof now shows every requirement for every Rule and thus is concluded. 
 \subsection{Termination and runtime via norm}
To argue about termination we will show that every Rule in the transition system increases the norm, and that the Norm is bound. To show that the Norm increases, we use the theorem \textit{algo\_step\_increases\_norm}. This lemma assumes that there is a step possible from $(S,F,T)$ to $(S',F',T')$ and that the invariant holds for $(S,F,T)$. The conclusion of this lemma is that the Norm of the first state is smaller than the Norm of the second state. 
\begin{myisabelle}
	\increasesnorm
\end{myisabelle}
To show this, we use a case distinction to argue about each Rule separately. For Rules two to four we show that one part of the Norm is strictly bigger on the new state than on the old and for the others we show that it is at least as big. Rule 1 is once again a special case where the first norm increases and the last one decreases. \\
To argue about cardinalities the proof uses the \textit{card\_mono} lemma from the standard library, that says if $X\subseteq X'$ and $X'$ is finite then $|X|\leq |X'|$ for any two stets $S$ and $S'$. The proof shows that any set on the right side is finite through bulidng an overapproximation that is finite and showing a subset relationship. To proof subset relationships for the norms, both sets are compared very detailed showing similarities or building a subset chain. To argue about the last three Rules two lemmata are important, \textit{output\_query\_retains\_some\_specific\_output} is used to show that \textit{process\_output\_query} does not change existing transitions, and \textit{process\_op\_query\_not\_none} is used for new transitions. Here the Proof uses the first lemma to sow subset relationships and the second one to show that a new item is in the sets of norm2 or norm3. \\
The lemma \textit{process\_op\_query\_not\_none} shows that if an output query has been proceeded for a input sequence $ip$ than that sequence can not be undefined for the tree.
\begin{myisabelle}
	\notnone
\end{myisabelle}
This lemma, once again requires and inducton, we have only one viable target with the input sequence. Since $ip$ is used for both \textit{process\_output\_query} and \textit{run} the proof can use the hypothesis after considering the possibility of the first transition being undefined.\\
Using this lemma for the Norm is straigth forward, e.g. in Rule 2 we can show that the follow transition previously undefined now has a definition increasing \textit{norm2}, for Rule 3 the existence of a defined transition is enougth to proof that the apartness relationship has expanded, and in Rule 4 we use the invariant, i.e. the property that all defined outputs are equal to the ouptut query (thanks to \textit{algo\_step\_keeps\_invar} also for the new tree) in tandem with both transitions being defined to show increase.

The property that the Norm increases shows progress, but to show Termination we need to provide a upper bond on the Norm. The function \textit{norm\_max} is the maximum possible Norm for any Basis $S$: 
\begin{myisabelle}
	\maxnorm
\end{myisabelle}
The proof that \textit{max\_Norm S} is bigger or equal than \textit{Norm (S,F,T)} for any $F,T$ if the invariant holds is important, and in isabelle works through giving supersets for the sets used in \textit{norm2} and \textit{norm3}. Showing that the Norm is bound can now be done by showing that the number of states in the Basis is bound. 
\begin{myisabelle}
\maxs
\end{myisabelle}
The lemma uses the assumption that a functional simulation exists, this is possible, because there exists a functional simulation for any state that is consistent with the invariant. Now it uses a contraposition argument, assuming that there are more states in $S$ than in $Q$. Thentotwo states $s1,s2\in S$ must exist that map to the same state with f $f\; s1=f\; s2$, but since every two states are apart $s1\#s2$ they can not map to the same state in a functional simulation, leading to a contradiction.\\
This upper bound for $S$ is less accurate than the bound proposed by Vandraager et.al \cite{vandraagerlsharp}, since Vandraagers Norm uses the number of Equivalence classes of the hidden Mealy Machine. We chose the number of states since it is easier to formalize, and gives an appropriate bound, still relying on the size of any hidden Mealy Machine. \\
Using these two lemmata, we now know the maximum Norm is $max\_norm\; Q$ and because every step of \textit{algo\_step} increases the norm, the algorithm has to terminate after $max\_norm\; Q$ steps. 

\subsection{Correctness}
To show corectness of the algorithm we show that the transition system terminates in a state, where any hypothesis is equal to the hidden Mealy Machine. To show correctness of a whole run we define a starting point for the algorithm $(\{[]\},\{\},(Node \; Map.empty))$ where the Basis only contains the starting node, the Frontier is the empty set and the tree only contains the starting node. Furthermore, show a run from start to finish we need a way of concatenating steps. So we define\textit{algo\_steps} as the concatenation from \textit{algo\_step} with itself. Now we can define our goal, we want to obtain a state $(S,F,T)$ that is reachable via \textit{algo\_steps} from the starting configuration, where the algorithm can not perform further steps. We will call a state where no further step can be taken a final state. We then want to show that there both esxist an hypothesis and that any hypothesis is equal to the hidden Mealy Mealy machine.
\begin{myisabelle}
	\corollary
\end{myisabelle}
The proof of final states require them to fulfill the invariant, since we have proven that \textit{algo\_step} retains the invariant, the proof now need to show that the starting state also fulfills the invariant. Then we can argue, that any final state that fulfills the invariant has a hypothesis, and any hypothesis for a final state that fulfills the invariant is equal to the hidden Mealy Machine. \\
Beacuse the empty state fulfills the invariant is trivial we focus on the other two lemmata. First we will proof the lemma that a hypothesis exists, to define the lemma we use the knowledge from \autoref{def:hypo} that a hypothesis exists if every transition from a Basis state is defined and no Frontier state is isolated, we use those two as assumptions, this holds for final state, since a application of Rule 1 or Rule 2 would be possible otherwise.
\begin{myisabelle}
	\existshypothesis
\end{myisabelle}
 Now this proof that a hypothesis function exists, uses an example. To build a hypothesis, the proof uses help function $f$ , $f$ will take a input list $i$ and return $i$ if it is a Basis state, and a Basis state that is not apart from $i$ if $i\in F$, and is not defined in any specific way if the state is outside of the Basis and the Frontier. This works, because every state in the Frontier is not apart from at least one state in the Basis. Now the proof describes a function that will be a hypothesis, this function takes a input list $s$ as state and a single input letter $i$, it will return a dummy value if either $s$ or the transition from $s$ with $i$ is undefined. If both are defined, it returns the output from the transition from $s$ with $i$ as well as the result of the function $f\; (s@[i])$ as the next state. Here is how the function looks in Isabelle, the output $none$ can be any possible output, it is not relevant for the hypothesis function.
 \begin{myisabelle}
 	\hypofunc
 \end{myisabelle}
Since a hypothesis only needs to work on the Basis states and all outgoing transitions and we assumed that all of those are defined, the proof now can show that $t$ is a hypothesis for the state $(S,F,T)$. \\
Now that we have proven that a hypothesis exists, the next step is to prove that this hypothesis is equal to a Mealy Machine $M$. For this we take the assumptions that $(S,F,T)$ is a final state that fulfills the invariant and $t$ is a hypothesis function for the state: 
\begin{myisabelle}
	\nostepeq
\end{myisabelle}
The proof of this theorem is crucial, but since no induction is possible, we need an auxiliary lemma. The auxiliary lemma proves the equality of all \textit{outs\_run\_Mealy} applications to one state of the Mealy Machine $q\in Q$ and one of the hypothesis $p$.It uses different assumptions so that the induction can work, one that the list $p$ is a Basis state because the hypothesis only works on Basis states, and one that shows the equality of both sates in the Mealy Machine. Since two equal states are not apart, the lemma assumes that the two states are not apart. 
\begin{myisabelle}
	\outsamenostep
\end{myisabelle}
The proof uses an induciton on the input string $inp$. The base case is trivial, but for the step of the induction it needs to make a case distinction, either the next state reached is part of the Basis or not, if the next state is part of the Basis, an easy application of the induction hypothesis can take place. Otherwise if the transition leaves the Basis, an application of the induction hypothesis is more difficult, because the non apartness is harder to show. For the rest of this proof we call the first letter of the input $a$, the state reached from the hypothesis $p'$ where $h\; (p,a) =(p',op)$ and the next state for the hidden Mealy Machine $q'$ where $f (q,a)= (q',op)$. To apply the induction hypothesis to the case where $p@[a]$ is not in the Basis, the proof needs to show that the state it can find in the Mealy Machine $p'm= state\_run\_Mealy\; f\;q_0\;p' $ is not apart from $q'$. It uses a clever contradiction to show that: if those two were apart, then $p@[a]$ and $p'$ would also be apart in the Mealy Machine, which is impossible, because the states are not apart in the complete observation tree and every difference query returns $None$.\\
Now using the lemmata in tandem we can show that the algorithm is correct.
\chapter{Conclusion}
In the context of this work we formalized the $L\#$ algorithm in Isabelle. To simplify the proof we changed the last Rule of the algorithm through adding a different query to the teacher. This change simplified formal verification of rule four. We also added explicit parsing of output queries, as no specific way to change the observation tree was mentioned in the original paper. Then we proved that the algorithm is correct and that it Terminates in a polynomial amount of time. One of the drawbacks of this work is that we did not show equality of the two different forms of Rule 4, and another one is that no executable version, where every part of the algorithm is written as a function rather than as a inductive, of this algorithm was proven.
\section{Future Work}
A proof of an executable version of the $L\#$ algorithm would improve the formalization further. In the context of the work we tried to make a formalization work, but did not achieve a proof or an fully executable function. The exact implementation of functions that obtain are hard to figure out and using an proofs using induction scheme on a function where the increase of the norm is the only metric that changes is even more difficult. Another improvement would formalize the equality of both Rule 4 versions, or include similar proofs for a transition system with the original Rule 4. In the context of this work this was not achieved because the details of \proccon\space are hard to understand and hard to formalize. Processing counterexamples would need a second big proof with some kind of invariant of the function. Within the limited time frame of this thesis those two extra goals where not reached. \\
Further steps would be to extend the proof for new extensions like $L\#$ for DFAs \cite{DBLP:conf/birthday/VaandragerS25} or the $L\#$ algorithm extended for mealy machines with Timers \cite{DBLP:journals/corr/abs-2403-02019}.
\bibliographystyle{plain} % or IEEEtran, apalike, etc.
\bibliography{ref} 
\end{document}